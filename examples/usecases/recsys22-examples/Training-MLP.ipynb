{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6eee7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd787f",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Training\n",
    "\n",
    "> Bagged representation of the input sequence + MLPBlock + Multi-classification layer with weight-tying\n",
    "\n",
    "Topics covered in this notebook:\n",
    "- Label smoothing\n",
    "- Temperature\n",
    "- Weight Tying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02150b86",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2b40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cudf\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from merlin.io import Dataset\n",
    "from merlin.schema import Tags\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "from merlin.models.tf.utils.tf_utils import extract_topk\n",
    "import numpy as np\n",
    "import merlin.models.tf as mm\n",
    "from merlin.models.tf import InputBlock\n",
    "from merlin.models.tf.models.base import Model\n",
    "from merlin.models.tf.blocks.core.aggregation import SequenceAggregation, SequenceAggregator\n",
    "from merlin.models.tf.blocks.core.transformations import (\n",
    "    ItemsPredictionWeightTying,\n",
    "    L2Norm,\n",
    "    LogitsTemperatureScaler,\n",
    ")\n",
    "from merlin.models.tf.inputs.embedding import EmbeddingOptions\n",
    "\n",
    "DATA_FOLDER = 'dressipi'\n",
    "DATA_PROCESSED_FOLDER = 'dressipi_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "520586bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'train/*.parquet'),shuffle=False)\n",
    "valid = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'valid/*.parquet'), shuffle=False)\n",
    "test_leaderboard = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'test_leaderboard/*.parquet'), shuffle=False)\n",
    "test_final = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'test_final/*.parquet'), shuffle=False)\n",
    "\n",
    "purchases = pd.read_csv(os.path.join(DATA_FOLDER, \"train_purchases.csv\"))\n",
    "item_map = pd.read_parquet(\n",
    "    os.path.join(\"categories\", \"unique.item_id.parquet\"))['item_id'].to_dict()\n",
    "session_map = pd.read_parquet(\n",
    "    os.path.join(\"categories\", \"unique.session_id.parquet\"))['session_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afa5f5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_id_list_seq</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.ITEM_ID, Tags.ITEM, Tags....</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>23566.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23566</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_id_last</td>\n",
       "      <td>(Tags.BINARY_CLASSIFICATION, Tags.ITEM_ID, Tag...</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>23566.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23566</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'item_id_list_seq', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.ITEM_ID: 'item_id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id.parquet', 'embedding_sizes': {'cardinality': 23566.0, 'dimension': 449.0}, 'domain': {'min': 0, 'max': 23566, 'name': 'item_id'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'item_id_last', 'tags': {'Tags.BINARY_CLASSIFICATION', <Tags.ITEM_ID: 'item_id'>, <Tags.TARGET: 'target'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id.parquet', 'embedding_sizes': {'cardinality': 23566.0, 'dimension': 449.0}, 'domain': {'min': 0, 'max': 23566, 'name': 'item_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_model = train.schema.select_by_name(['item_id_list_seq', 'item_id_last'])\n",
    "schema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f37d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "tmp = train.compute()\n",
    "start_month_train = tmp[tmp['date_last'] <= datetime.datetime(2021, 4, 1)]\n",
    "last_month_train = tmp[tmp['date_first'] >= datetime.datetime(2021, 4, 1)]\n",
    "start_month_train =  Dataset(start_month_train, schema=schema_model, shuffle=True)\n",
    "last_month_train =  Dataset(last_month_train, schema=schema_model, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ec38a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((920830, 30), (848637, 30), (72193, 30))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape,start_month_train.compute().shape,last_month_train.compute().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb096463",
   "metadata": {},
   "source": [
    "## Model\n",
    "- A sequential-MLP with average of the sequence as final representation\n",
    "\n",
    "The model contains:\n",
    "- A InputBlock which takes sequential features, concatenate them and return the sequence of interaction embeddings\n",
    "- MLPBlock to get the sequence of hidden representation\n",
    "- Multi-Classiffication prediction head\n",
    "    - Layer normalization\n",
    "    - Item weight-tying\n",
    "    - transfom labels to one-hot encoding representation for metrics \n",
    "    - softmax temperature to reduce model's over confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825a37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-10 02:41:43.505801: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "inputs = InputBlock(\n",
    "        schema_model,\n",
    "        aggregation='concat',\n",
    "        seq=True,\n",
    "        max_seq_length=20,\n",
    "        embedding_options=mm.EmbeddingOptions(embedding_dim_default=128),\n",
    "        split_sparse=True,\n",
    ")\n",
    "\n",
    "dense_block = mm.MLPBlock(\n",
    "                [64, 128],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "                dropout=0.01,\n",
    "            )\n",
    "\n",
    "prediction_call = L2Norm().connect(\n",
    "    ItemsPredictionWeightTying(schema_model), \n",
    "    mm.LabelToOneHot(), \n",
    "    LogitsTemperatureScaler(temperature=2)\n",
    ")\n",
    "\n",
    "task = mm.MultiClassClassificationTask(\n",
    "    target_name=\"item_id_last\",\n",
    "    pre=prediction_call\n",
    ")\n",
    "\n",
    "model = Model(inputs, dense_block, SequenceAggregator(SequenceAggregation.MEAN), task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d632f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=3e-1,\n",
    "    clipnorm=True\n",
    ")\n",
    "\n",
    "# model.compile(optimizer=opt, run_eagerly=False)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    run_eagerly=True,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.2),\n",
    "    metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[100])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9763c",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e858433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6630/6630 [==============================] - 410s 60ms/step - loss: 6.7056 - recall_at_100: 0.5242 - mrr_at_100: 0.2414 - ndcg_at_100: 0.2989 - map_at_100: 0.2414 - precision_at_100: 0.0052 - regularization_loss: 0.0000e+00 - val_loss: 7.0263 - val_recall_at_100: 0.6485 - val_mrr_at_100: 0.3405 - val_ndcg_at_100: 0.4054 - val_map_at_100: 0.3405 - val_precision_at_100: 0.0065 - val_regularization_loss: 0.0000e+00\n",
      "CPU times: user 7min 25s, sys: 11.5 s, total: 7min 36s\n",
      "Wall time: 7min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(start_month_train, validation_data=last_month_train, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f58452",
   "metadata": {},
   "source": [
    "## Inference\n",
    "MRR score on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3443e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mrr(rec_list,target):\n",
    "    mrr = 0\n",
    "    for a,b in zip(rec_list,target):\n",
    "        rank = np.argmax(np.array(a)==b)\n",
    "        if rank != 0:\n",
    "            mrr += (1 / (1 + rank))\n",
    "    return mrr/(target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e1c8d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 14.8 s, total: 2min 27s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid = Dataset(\n",
    "    [DATA_PROCESSED_FOLDER+'/valid/*.parquet'], \n",
    "    part_mem_fraction=0.01, \n",
    "    shuffle=False)\n",
    "x = BatchedDataset(\n",
    "    valid, \n",
    "    batch_size=256, \n",
    "    shuffle=False, \n",
    ")\n",
    "predictions = model.predict(x)\n",
    "\n",
    "topk_predicted = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    _, topk_indices = tf.math.top_k(predictions[i, :], 100)\n",
    "    topk_predicted.append(topk_indices.numpy().reshape(1, 100))\n",
    "\n",
    "top_predicted = np.concatenate(topk_predicted)\n",
    "\n",
    "valid_data = valid.to_ddf().compute().to_pandas()\n",
    "valid_data['session_id'] = valid_data.session_id.map(session_map)\n",
    "valid_data = pd.merge(valid_data, purchases, on='session_id')[['session_id', 'item_id']]\n",
    "\n",
    "valid_data['top100_predicted'] = top_predicted.tolist()\n",
    "valid_data['top100_predicted']= valid_data['top100_predicted'].apply(lambda x: [item_map[i] for i in x])\n",
    "\n",
    "mrr_eval = compute_mrr(valid_data['top100_predicted'], valid_data['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edd7b811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06950263758217776"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2a341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
