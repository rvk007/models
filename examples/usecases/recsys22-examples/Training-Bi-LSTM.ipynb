{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879ec9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ca08d",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Training\n",
    "\n",
    "> Bagged representation of the input sequence + Bi-LSTM Block + MLPBlock + Multi-classification layer with weight-tying\n",
    "\n",
    "Topics covered in this notebook:\n",
    "- Utilizing Bi-LSTM layer with Merlin models\n",
    "- Label smoothing\n",
    "- Temperature\n",
    "- Weight Tying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af57ac5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d075bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 18:00:40.120616: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-11 18:00:49.066734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16255 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "2022-07-11 18:00:49.068978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30677 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "2022-07-11 18:00:49.073064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30677 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2022-07-11 18:00:49.081797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30677 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cudf\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from merlin.io import Dataset\n",
    "from merlin.schema import Tags\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "from merlin.models.tf.utils.tf_utils import extract_topk\n",
    "import numpy as np\n",
    "import merlin.models.tf as mm\n",
    "from merlin.models.tf import InputBlock\n",
    "from merlin.models.tf.models.base import Model\n",
    "from merlin.models.tf.blocks.core.aggregation import SequenceAggregation, SequenceAggregator\n",
    "from merlin.models.tf.blocks.core.transformations import (\n",
    "    ItemsPredictionWeightTying,\n",
    "    L2Norm,\n",
    "    LogitsTemperatureScaler,\n",
    ")\n",
    "from merlin.models.tf.inputs.embedding import EmbeddingOptions\n",
    "\n",
    "DATA_FOLDER = 'dressipi'\n",
    "DATA_PROCESSED_FOLDER = 'dressipi_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9819d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1292: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'train/*.parquet'),shuffle=False)\n",
    "valid = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'valid/*.parquet'), shuffle=False)\n",
    "test_leaderboard = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'test_leaderboard/*.parquet'), shuffle=False)\n",
    "test_final = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'test_final/*.parquet'), shuffle=False)\n",
    "\n",
    "purchases = pd.read_csv(os.path.join(DATA_FOLDER, \"train_purchases.csv\"))\n",
    "item_map = pd.read_parquet(\n",
    "    os.path.join(\"categories\", \"unique.item_id.parquet\"))['item_id'].to_dict()\n",
    "session_map = pd.read_parquet(\n",
    "    os.path.join(\"categories\", \"unique.session_id.parquet\"))['session_id'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae2ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_id_list_seq</td>\n",
       "      <td>(Tags.LIST, Tags.ITEM, Tags.SEQUENCE, Tags.CAT...</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>23566.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23566</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_id_last</td>\n",
       "      <td>(Tags.ITEM, Tags.CATEGORICAL, Tags.BINARY_CLAS...</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>23566.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23566</td>\n",
       "      <td>item_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'item_id_list_seq', 'tags': {<Tags.LIST: 'list'>, <Tags.ITEM: 'item'>, <Tags.SEQUENCE: 'sequence'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id.parquet', 'embedding_sizes': {'cardinality': 23566.0, 'dimension': 449.0}, 'domain': {'min': 0, 'max': 23566, 'name': 'item_id'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'item_id_last', 'tags': {<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>, 'Tags.BINARY_CLASSIFICATION', <Tags.TARGET: 'target'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id.parquet', 'embedding_sizes': {'cardinality': 23566.0, 'dimension': 449.0}, 'domain': {'min': 0, 'max': 23566, 'name': 'item_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_model = train.schema.select_by_name(['item_id_list_seq', 'item_id_last'])\n",
    "schema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b80b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "tmp = train.compute()\n",
    "start_month_train = tmp[tmp['date_last'] <= datetime.datetime(2021, 4, 1)]\n",
    "last_month_train = tmp[tmp['date_first'] >= datetime.datetime(2021, 4, 1)]\n",
    "start_month_train =  Dataset(start_month_train, schema=schema_model, shuffle=True)\n",
    "last_month_train =  Dataset(last_month_train, schema=schema_model, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5270c74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((920830, 30), (848637, 30), (72193, 30))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape,start_month_train.compute().shape,last_month_train.compute().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262df755",
   "metadata": {},
   "source": [
    "## Model\n",
    "- A Bi-LSTM Block with MLP for MultiClassification prediction task\n",
    "\n",
    "The model contains:\n",
    "- A InputBlock which takes sequential features, concatenate them and return the sequence of interaction embeddings\n",
    "- Bi-LSTM block to get the sequence of hidden representation\n",
    "- MLPBlock to get the sequence of hidden representation\n",
    "- Multi-Classiffication prediction head\n",
    "    - Layer normalization\n",
    "    - Item weight-tying\n",
    "    - transfom labels to one-hot encoding representation for metrics \n",
    "    - softmax temperature to reduce model's over confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37bdbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(mm.Block):\n",
    "    \"\"\"\n",
    "    Build BiLSTM model\n",
    "    It requires a dictionary input with the sequence of interaction embeddings `interactions`\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim= 64, **kwargs):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=False, dropout=0.05,\n",
    "                                   kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.lstm = tf.keras.layers.Bidirectional(lstm)\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs, training=False, **kwargs) -> tf.Tensor:  \n",
    "        interactions = inputs['input_sequence']\n",
    "        sequence_representation = self.lstm(interactions)\n",
    "        return sequence_representation\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = input_shape['input_sequence']\n",
    "        return (input_shape[0], input_shape[1], self.hidden_dim*2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9313d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 18:00:57.695645: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "inputs = InputBlock(\n",
    "        schema_model,\n",
    "        aggregation='concat',\n",
    "        seq=True,\n",
    "        max_seq_length=20,\n",
    "        embedding_options=mm.EmbeddingOptions(\n",
    "            embedding_dim_default=128,\n",
    "            infer_embedding_sizes=True,\n",
    "            infer_embedding_sizes_multiplier=2,\n",
    "            infer_embeddings_ensure_dim_multiple_of_8=True\n",
    "        ),\n",
    "        split_sparse=True,\n",
    ")\n",
    "\n",
    "bilstm = BiLSTM(hidden_dim=64)\n",
    "dense_block = mm.ParallelBlock({'input_sequence': inputs}).connect(bilstm)\n",
    "\n",
    "mlp_block = mm.MLPBlock(\n",
    "                [64, 32],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "                dropout=0.01,\n",
    "            )\n",
    "\n",
    "prediction_call = L2Norm().connect(\n",
    "    ItemsPredictionWeightTying(schema_model), \n",
    "    mm.LabelToOneHot(), \n",
    "    LogitsTemperatureScaler(temperature=2)\n",
    ")\n",
    "\n",
    "task = mm.MultiClassClassificationTask(\n",
    "    target_name=\"item_id_last\",\n",
    "    pre=prediction_call\n",
    ")\n",
    "\n",
    "model = Model(dense_block, mlp_block, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371744dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=3e-1,\n",
    "    clipnorm=True\n",
    ")\n",
    "\n",
    "# model.compile(optimizer=opt, run_eagerly=False)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    run_eagerly=True,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.2),\n",
    "    metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[100])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343fca3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a348359f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 18:01:19.839452: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6630/6630 [==============================] - 654s 97ms/step - loss: 25.5581 - recall_at_100: 0.3156 - mrr_at_100: 0.0694 - ndcg_at_100: 0.1148 - map_at_100: 0.0694 - precision_at_100: 0.0032 - regularization_loss: 17.1317 - val_loss: 29.1731 - val_recall_at_100: 0.2236 - val_mrr_at_100: 0.0553 - val_ndcg_at_100: 0.0871 - val_map_at_100: 0.0553 - val_precision_at_100: 0.0022 - val_regularization_loss: 19.9265\n",
      "CPU times: user 11min 32s, sys: 14.5 s, total: 11min 47s\n",
      "Wall time: 11min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(start_month_train, validation_data=last_month_train, batch_size=128, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860adf42",
   "metadata": {},
   "source": [
    "## Inference\n",
    "MRR score on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a27f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mrr(rec_list,target):\n",
    "    mrr = 0\n",
    "    for a,b in zip(rec_list,target):\n",
    "        rank = np.argmax(np.array(a)==b)\n",
    "        if rank != 0:\n",
    "            mrr += 1 / (1 + rank)\n",
    "    return mrr/(target.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec96066",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = Dataset(\n",
    "    [DATA_PROCESSED_FOLDER+'/valid/*.parquet'], \n",
    "    part_mem_fraction=0.01, \n",
    "    shuffle=False)\n",
    "x = BatchedDataset(\n",
    "    valid, \n",
    "    batch_size=256, \n",
    "    shuffle=False, \n",
    ")\n",
    "predictions = model.predict(x)\n",
    "\n",
    "topk_predicted, topk_scores = [], []\n",
    "k = 1000\n",
    "for i in range(predictions.shape[0]):\n",
    "    top_scores, top_indices = tf.math.top_k(predictions[i, :], k)\n",
    "    topk_predicted.append(top_indices.numpy().reshape(1, k))\n",
    "    topk_scores.append(top_scores.numpy().reshape(1, k))\n",
    "\n",
    "topk_predicted = np.concatenate(topk_predicted)\n",
    "topk_scores= np.concatenate(topk_scores)\n",
    "\n",
    "valid_data = valid.to_ddf().compute().to_pandas()\n",
    "valid_data['session_id'] = valid_data.session_id.map(session_map)\n",
    "valid_data = pd.merge(valid_data, purchases, on='session_id')[['session_id', 'item_id']]\n",
    "\n",
    "valid_data['topk_predicted'] = list(topk_predicted.astype(np.int32))\n",
    "valid_data['topk_scores'] = list(topk_scores.astype(np.float32))\n",
    "\n",
    "valid_data['topk_predicted'] = valid_data['topk_predicted'].apply(lambda x: [item_map[i] for i in x])\n",
    "\n",
    "valid_data['top100'] = valid_data['topk_predicted'].apply(lambda x: x[:100])\n",
    "\n",
    "mrr_eval = compute_mrr(valid_data['top100'], valid_data['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4857a0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01572088760854956"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab1e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
