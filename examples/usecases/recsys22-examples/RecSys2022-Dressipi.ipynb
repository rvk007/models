{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dc451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a58d3",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Recsys2022 Challenge \n",
    "\n",
    "NVIDIA-Merlin team participated in [Recsys2022 challenge](http://www.recsyschallenge.com/2022/index.html) and secured 3rd position. This notebook contains the various techniques used in the solution.\n",
    "\n",
    "### Learning Objective\n",
    "In this notebook, we will learn the importance of the concepts that improved the results of the competition significantly.\n",
    "\n",
    "- ##### Label smoothing\n",
    "     When the probabilities predicted by a Classification model are higher than its accuracy we say the model is overconfident. It can be prevented by using Label smoothing. This technique basically, transforms One-hot encoded labels into smoothed labels. \n",
    "$$  \\begin{array}{l}\n",
    "y_{l} \\ =\\ ( 1\\ -\\ \\alpha \\ ) \\ *\\ y_{o} \\ +\\ ( \\alpha \\ /\\ L)\\\\\n",
    "\\alpha :\\ Label\\ smoothing\\\\\n",
    "L:\\ Total\\ number\\ of\\ label\\ classes\\\\\n",
    "y_{o} :\\ One-hot\\ encoded\\ label\\ vector\n",
    "\\end{array}\n",
    "$$\n",
    "When α is 0, we have the original one-hot encoded labels, and as α increases, we move towards smoothed labels. Read [this](https://arxiv.org/abs/1906.02629) paper to learn more about it.\n",
    "\n",
    "\n",
    "- ##### Temperature Scaling\n",
    "    Similar to Label Smoothing, Temperature Scaling is done to reduce the overconfidence of a model. In this, we divide the logits (inputs to the softmax function) by a scalar parameter (T) . For more information on Temperature Scaling read [this](https://arxiv.org/pdf/1706.04599.pdf) paper.\n",
    "$$ softmax\\ =\\ \\frac{e\\ ^{( z_{i} \\ /\\ \\ T)}}{\\sum _{j} \\ e^{( z_{j} \\ /\\ T)} \\ } $$\n",
    "\n",
    "\n",
    "- ##### Weight Tying\n",
    "In this technique, we share the Embedding layer's weights which is used to convert the input to embeddings, as the softmax weights,  to convert hidden layer output to softmax layer output. This drastically reduces the number of parameters and allows the model to train better. For more information read [this](https://arxiv.org/pdf/1608.05859v3.pdf) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dac596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 05:53:38.124793: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-16 05:53:40.057935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16255 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB-LS, pci bus id: 0000:86:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cupy\n",
    "import cudf\n",
    "import dask_cudf\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import nvtabular as nvt\n",
    "from merlin.dag import ColumnSelector\n",
    "from merlin.io import Dataset\n",
    "from merlin.schema import Schema, Tags\n",
    "from nvtabular.ops import (\n",
    "    AddMetadata,\n",
    ")\n",
    "from merlin.schema.tags import Tags\n",
    "from utils import get_drepessi_recsys2022_dataset\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from merlin.io import Dataset\n",
    "from merlin.schema import Tags\n",
    "from tensorflow.keras import regularizers\n",
    "from merlin.models.tf.dataset import BatchedDataset\n",
    "from merlin.models.tf.utils.tf_utils import extract_topk\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.models.tf import InputBlock\n",
    "from merlin.models.tf.models.base import Model\n",
    "from merlin.models.tf.core.aggregation import SequenceAggregation, SequenceAggregator\n",
    "from merlin.models.tf.core.transformations import (\n",
    "    ItemsPredictionWeightTying,\n",
    "    L2Norm,\n",
    "    LogitsTemperatureScaler,\n",
    ")\n",
    "\n",
    "\n",
    "DATA_FOLDER = 'dressipi'\n",
    "DATA_PROCESSED_FOLDER = 'dressipi_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf858cf2",
   "metadata": {},
   "source": [
    "## Dressipi\n",
    "The [Dressipi](http://www.recsyschallenge.com/2022/dataset.html) dataset contains 1.1 M online retail sessions that resulted in a purchase. It provides details about items that were viewed in a session, the item purchased at the end of the session and numerous features of those items. The task of this competition was, given a sequence of items predict which item will be purchased at the end of a session.\n",
    "\n",
    "\n",
    "<img src=\"images/dressipi.JPG\" alt=\"dressipi_dataset\" style=\"width: 400px; float: center;\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0c598",
   "metadata": {},
   "source": [
    "#### Load the Dressipi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2df4579",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = get_drepessi_recsys2022_dataset(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596826c7",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset contains:\n",
    "- `session_id`, id of a session, in which a user viewed and purchased an item. \n",
    "- `item_id` which was viewed at a given `timestamp` in a session\n",
    "- `purchase_id` which is the id of item bought at the end of the session. \n",
    "In addition to `timestamp`, we have `day` and `date` features for representing the chronological order in which items were viewed.\n",
    "\n",
    "The items in the Dresspi dataset had a many features out of which we took 22 most important features, namely \n",
    "`f_3 ,f_4 ,f_5 ,f_7 ,f_17 ,f_24 ,f_30 ,f_45 ,f_46 ,f_47 ,f_50 ,f_53 ,f_55 ,f_56 ,f_58 ,f_61 ,f_63 ,f_65 ,f_68 ,f_69 ,f_72 ,f_73 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbb6f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_30</th>\n",
       "      <th>...</th>\n",
       "      <th>f_61</th>\n",
       "      <th>f_63</th>\n",
       "      <th>f_65</th>\n",
       "      <th>f_68</th>\n",
       "      <th>f_69</th>\n",
       "      <th>f_72</th>\n",
       "      <th>f_73</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>day</th>\n",
       "      <th>purchase_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3232</td>\n",
       "      <td>15043</td>\n",
       "      <td>2020-02-25 17:19:31.734</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1582651171734</td>\n",
       "      <td>55</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3232</td>\n",
       "      <td>15043</td>\n",
       "      <td>2020-02-25 19:39:03.303</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1582659543303</td>\n",
       "      <td>55</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3232</td>\n",
       "      <td>15043</td>\n",
       "      <td>2020-02-25 19:39:36.174</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>462.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>744.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1582659576174</td>\n",
       "      <td>55</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3232</td>\n",
       "      <td>8486</td>\n",
       "      <td>2020-02-25 19:41:55.006</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>898.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1582659715006</td>\n",
       "      <td>55</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3232</td>\n",
       "      <td>24858</td>\n",
       "      <td>2020-02-25 19:42:46.150</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>706.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1582659766150</td>\n",
       "      <td>55</td>\n",
       "      <td>1727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  item_id                    date  f_3  f_4  f_5    f_7  f_17  \\\n",
       "0        3232    15043 2020-02-25 17:19:31.734 -1.0 -1.0 -1.0  394.0  -1.0   \n",
       "1        3232    15043 2020-02-25 19:39:03.303 -1.0 -1.0 -1.0  394.0  -1.0   \n",
       "2        3232    15043 2020-02-25 19:39:36.174 -1.0 -1.0 -1.0  394.0  -1.0   \n",
       "3        3232     8486 2020-02-25 19:41:55.006 -1.0 -1.0 -1.0    2.0  -1.0   \n",
       "4        3232    24858 2020-02-25 19:42:46.150 -1.0 -1.0 -1.0    2.0  -1.0   \n",
       "\n",
       "   f_24  f_30  ...   f_61  f_63  f_65   f_68   f_69   f_72  f_73  \\\n",
       "0  -1.0  -1.0  ...  462.0  -1.0  -1.0  744.0  885.0   75.0  -1.0   \n",
       "1  -1.0  -1.0  ...  462.0  -1.0  -1.0  744.0  885.0   75.0  -1.0   \n",
       "2  -1.0  -1.0  ...  462.0  -1.0  -1.0  744.0  885.0   75.0  -1.0   \n",
       "3  -1.0  -1.0  ...  898.0  -1.0  -1.0  596.0  780.0  655.0  91.0   \n",
       "4  -1.0  -1.0  ...  706.0  -1.0  -1.0  204.0  362.0   75.0  -1.0   \n",
       "\n",
       "       timestamp  day  purchase_id  \n",
       "0  1582651171734   55         1727  \n",
       "1  1582659543303   55         1727  \n",
       "2  1582659576174   55         1727  \n",
       "3  1582659715006   55         1727  \n",
       "4  1582659766150   55         1727  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cbea6d",
   "metadata": {},
   "source": [
    "Let's encode the `item_id` and `purchase_id` explicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e5f42",
   "metadata": {},
   "source": [
    "## Feature Engineering with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50949a5",
   "metadata": {},
   "source": [
    "### Categorify\n",
    "\n",
    "Let’s perform categorical encoding on the entire train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68cbfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1292: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 899 ms, total: 3.08 s\n",
      "Wall time: 7.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "item_features_names = [col for col in train.columns if 'f_' in col]\n",
    "cat_features = ['session_id', ['item_id', 'purchase_id']] + item_features_names >> nvt.ops.Categorify()\n",
    "\n",
    "features = ['timestamp','date',] + cat_features\n",
    "dataset = Dataset(cudf.concat([train,valid]))\n",
    "workflow0 = nvt.Workflow(features)\n",
    "workflow0.fit(dataset)\n",
    "\n",
    "# transform data\n",
    "train_0 = workflow0.transform(Dataset(train))\n",
    "valid_0 = workflow0.transform(Dataset(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74264e1a",
   "metadata": {},
   "source": [
    "### GroupBy\n",
    "\n",
    "Now let’s group the user interactions in a session. The resultant row will have a sequence of encoded items ids with which a user interacted. We will also add features like the last item the user viewed, the sequence of interactions timestamps, item id of the purchased item etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b822c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 1.76 s, total: 3.02 s\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = train_0.head().columns.tolist()\n",
    "\n",
    "# Define Groupby Operator\n",
    "to_aggregate = {\n",
    "    'date': [\"first\", \"last\"],\n",
    "    'item_id': [\"last\", \"list\"],\n",
    "    'timestamp': [\"list\"],\n",
    "    'purchase_id': ['first'],\n",
    "}\n",
    "for name in item_features_names: \n",
    "    to_aggregate[name] = ['list']\n",
    "    \n",
    "groupby_features = features >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id\"], \n",
    "    sort_cols=[\"date\"],\n",
    "    aggs= to_aggregate,\n",
    "    name_sep=\"_\")\n",
    "\n",
    "# Add tags needed for the t4rec models definition\n",
    "item_last = groupby_features['item_id_last'] >> nvt.ops.AddMetadata(tags=[Tags.ITEM, Tags.ITEM_ID, Tags.CATEGORICAL])\n",
    "item_list = groupby_features['item_id_list'] >> nvt.ops.AddMetadata(tags=[Tags.ITEM, Tags.ITEM_ID, Tags.LIST, Tags.SEQUENCE, Tags.CATEGORICAL])\n",
    "feature_list = groupby_features[[name+'_list' for name in item_features_names]]>> nvt.ops.AddMetadata(tags=[Tags.SEQUENCE, Tags.ITEM, Tags.LIST])\n",
    "other_features = groupby_features['session_id', 'date_first', 'date_last','timestamp_list']\n",
    "target_feature = groupby_features['purchase_id_first'] >> nvt.ops.AddMetadata(tags=[Tags.TARGET])\n",
    "\n",
    "workflow1 = nvt.Workflow(item_last + item_list + feature_list + other_features + target_feature)\n",
    "workflow1.fit(train_0)\n",
    "\n",
    "# transform data\n",
    "train_1 = workflow1.transform(train_0)\n",
    "valid_1 = workflow1.transform(valid_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df058756",
   "metadata": {},
   "source": [
    "### Truncate and Padding for a Maximum Sequence Length\n",
    "\n",
    "Since we want to train a sequence of interactions, the length of each interaction needs to be the same. Let’s truncate all sequences to a fixed-size of 20. The sequences which are shorter than 20 are padded by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8748ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSIONS_MAX_LENGTH = 3\n",
    "list_cols = [col for col in train_1.head().columns if 'list' in col and 'date' not in col]\n",
    "truncated_features = list_cols >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH, pad=True) >> nvt.ops.Rename(postfix = '_seq')\n",
    "\n",
    "final_features = [\n",
    "    'session_id', 'date_first', 'date_last', 'item_id_list', 'item_id_last', 'purchase_id_first'\n",
    "]\n",
    "\n",
    "workflow2 = nvt.Workflow(final_features + truncated_features)\n",
    "workflow2.fit(train_1)\n",
    "\n",
    "# transform data\n",
    "train_2 = workflow2.transform(train_1)\n",
    "valid_2 = workflow2.transform(valid_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae62f8",
   "metadata": {},
   "source": [
    "### Save processed data to Parquet files\n",
    "\n",
    "Now let's save the data for training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bbc8597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 19.9 s, total: 32.7 s\n",
      "Wall time: 52.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ds = Dataset(train_2.to_ddf().sort_values('date_last'), schema=train_2.schema)\n",
    "valid_ds = Dataset(valid_2.to_ddf().sort_values('date_last'), schema=valid_2.schema)\n",
    "\n",
    "train_ds.to_parquet(os.path.join(DATA_PROCESSED_FOLDER, \"train/\"), output_files=10)\n",
    "valid_ds.to_parquet(os.path.join(DATA_PROCESSED_FOLDER, \"valid/\"), output_files=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4eac01",
   "metadata": {},
   "source": [
    "## Training - MLP\n",
    "\n",
    "A Sequential- Multi-Layer Perceptron model with average of the sequence as final representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54bcf38",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce9b290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "LEARNING_RATE = 0.2 #3e-1\n",
    "CLIPNORM = True\n",
    "DROPOUT= 0.2 \n",
    "LABEL_SMOOTHING = 0.2\n",
    "TEMPERATURE_SCALING = 2\n",
    "OPTIMIZER_NAME = 'adam'\n",
    "LOSS='CategoricalCrossentropy'\n",
    "\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75010de1",
   "metadata": {},
   "source": [
    "#### Load the processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcde20d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:1292: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'train/*.parquet'), shuffle=False,)\n",
    "valid = Dataset(os.path.join(DATA_PROCESSED_FOLDER, 'valid/*.parquet'), shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ca38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import merlin.models.tf.dataset as tf_dataloader\n",
    "\n",
    "train_dl = tf_dataloader.BatchedDataset(\n",
    "    train,\n",
    "    batch_size = 512,\n",
    "    shuffle=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca6283",
   "metadata": {},
   "source": [
    "#### Schema \n",
    "Let’s visualize the schema. From this we will select features for training the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67014089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_id_list_seq</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.ITEM, Tags.ITEM_ID, Tags....</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timestamp_list_seq</td>\n",
       "      <td>(Tags.LIST)</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>session_id</td>\n",
       "      <td>(Tags.CATEGORICAL)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.session_id.parquet</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000001.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>date_first</td>\n",
       "      <td>()</td>\n",
       "      <td>float64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>date_last</td>\n",
       "      <td>()</td>\n",
       "      <td>float64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>item_id_list</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.ITEM, Tags.ITEM_ID, Tags....</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>item_id_last</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM, Tags.ITEM_ID)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>purchase_id_first</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.TARGET)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'item_id_list_seq', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'timestamp_list_seq', 'tags': {<Tags.LIST: 'list'>}, 'properties': {}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'session_id', 'tags': {<Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.session_id.parquet', 'embedding_sizes': {'cardinality': 1000001.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 1000001}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'date_first', 'tags': set(), 'properties': {}, 'dtype': dtype('float64'), 'is_list': False, 'is_ragged': False}, {'name': 'date_last', 'tags': set(), 'properties': {}, 'dtype': dtype('float64'), 'is_list': False, 'is_ragged': False}, {'name': 'item_id_list', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': True}, {'name': 'item_id_last', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'purchase_id_first', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.TARGET: 'target'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cbf7f",
   "metadata": {},
   "source": [
    "In this model, we will only use two features `item_id_last` and `item_id_list_seq` for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362ea972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_id_list_seq</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.ITEM, Tags.ITEM_ID, Tags....</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23619</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_id_last</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ITEM, Tags.ITEM_ID)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23619</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purchase_id_first</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.TARGET)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23619</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'item_id_list_seq', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'item_id_last', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}, {'name': 'purchase_id_first', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.TARGET: 'target'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_model = train.schema.select_by_name(['item_id_list_seq', 'item_id_last', 'purchase_id_first'])\n",
    "schema_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c779f3",
   "metadata": {},
   "source": [
    "Let's visualise the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3feee3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id_list_seq</th>\n",
       "      <th>timestamp_list_seq</th>\n",
       "      <th>session_id</th>\n",
       "      <th>date_first</th>\n",
       "      <th>date_last</th>\n",
       "      <th>item_id_list</th>\n",
       "      <th>item_id_last</th>\n",
       "      <th>purchase_id_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5726, 0, 0]</td>\n",
       "      <td>[1577836848505, 0, 0]</td>\n",
       "      <td>993759</td>\n",
       "      <td>2020-01-01 00:00:48.505</td>\n",
       "      <td>2020-01-01 00:00:48.505</td>\n",
       "      <td>[5726]</td>\n",
       "      <td>5726</td>\n",
       "      <td>14805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[16573, 16573, 0]</td>\n",
       "      <td>[1577837388157, 1577837392394, 0]</td>\n",
       "      <td>557284</td>\n",
       "      <td>2020-01-01 00:09:48.157</td>\n",
       "      <td>2020-01-01 00:09:52.394</td>\n",
       "      <td>[16573, 16573]</td>\n",
       "      <td>16573</td>\n",
       "      <td>14882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[670, 0, 0]</td>\n",
       "      <td>[1577837555593, 0, 0]</td>\n",
       "      <td>810825</td>\n",
       "      <td>2020-01-01 00:12:35.593</td>\n",
       "      <td>2020-01-01 00:12:35.593</td>\n",
       "      <td>[670]</td>\n",
       "      <td>670</td>\n",
       "      <td>14660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[10107, 0, 0]</td>\n",
       "      <td>[1577837569201, 0, 0]</td>\n",
       "      <td>696569</td>\n",
       "      <td>2020-01-01 00:12:49.201</td>\n",
       "      <td>2020-01-01 00:12:49.201</td>\n",
       "      <td>[10107]</td>\n",
       "      <td>10107</td>\n",
       "      <td>13320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[8165, 3199, 11865]</td>\n",
       "      <td>[1577837545450, 1577837571259, 1577837656096]</td>\n",
       "      <td>491528</td>\n",
       "      <td>2020-01-01 00:12:25.450</td>\n",
       "      <td>2020-01-01 00:14:16.096</td>\n",
       "      <td>[8165, 3199, 11865]</td>\n",
       "      <td>11865</td>\n",
       "      <td>8285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id_list_seq                             timestamp_list_seq  \\\n",
       "0         [5726, 0, 0]                          [1577836848505, 0, 0]   \n",
       "1    [16573, 16573, 0]              [1577837388157, 1577837392394, 0]   \n",
       "2          [670, 0, 0]                          [1577837555593, 0, 0]   \n",
       "3        [10107, 0, 0]                          [1577837569201, 0, 0]   \n",
       "4  [8165, 3199, 11865]  [1577837545450, 1577837571259, 1577837656096]   \n",
       "\n",
       "   session_id              date_first               date_last  \\\n",
       "0      993759 2020-01-01 00:00:48.505 2020-01-01 00:00:48.505   \n",
       "1      557284 2020-01-01 00:09:48.157 2020-01-01 00:09:52.394   \n",
       "2      810825 2020-01-01 00:12:35.593 2020-01-01 00:12:35.593   \n",
       "3      696569 2020-01-01 00:12:49.201 2020-01-01 00:12:49.201   \n",
       "4      491528 2020-01-01 00:12:25.450 2020-01-01 00:14:16.096   \n",
       "\n",
       "          item_id_list  item_id_last  purchase_id_first  \n",
       "0               [5726]          5726              14805  \n",
       "1       [16573, 16573]         16573              14882  \n",
       "2                [670]           670              14660  \n",
       "3              [10107]         10107              13320  \n",
       "4  [8165, 3199, 11865]         11865               8285  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949903cf",
   "metadata": {},
   "source": [
    "#### Build the Model\n",
    "Now we will create an InputBlock which takes sequential features, concatenate them and return the sequence of interaction embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f62b2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_options = mm.EmbeddingOptions(\n",
    "        embedding_dims = None,\n",
    "        embedding_dim_default=256,\n",
    "        infer_embedding_sizes=False,\n",
    ")\n",
    "\n",
    "input_block = InputBlock(\n",
    "    schema_model.select_by_name(['item_id_list_seq', 'item_id_last']), \n",
    "    aggregation='concat',\n",
    "    embedding_options = emb_options\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938fcce",
   "metadata": {},
   "source": [
    "The Multi-Classiffication Prediction head will have\n",
    "- Layer Normalization\n",
    "- Weight Tying\n",
    "- Labels as One-hot encoded vectors, used for label smoothing \n",
    "- Temperature Scaling to reduce the overconfidence of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17bc4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_call = L2Norm().connect(\n",
    "    ItemsPredictionWeightTying(schema_model), \n",
    "    mm.LabelToOneHot(),\n",
    "    LogitsTemperatureScaler(temperature=TEMPERATURE_SCALING)\n",
    ")\n",
    "\n",
    "prediction_task = mm.MultiClassClassificationTask(\n",
    "    target_name=\"purchase_id_first\",\n",
    "    pre=prediction_call,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87683ce7",
   "metadata": {},
   "source": [
    "Now, we will build a model with a MLPBlock, to get the sequence of hidden representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aabb868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 05:55:20.517803: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model_mlp = mm.Model.from_block(\n",
    "    mm.MLPBlock([128,256], no_activation_last_layer=True, dropout=0.2),\n",
    "    schema_model, \n",
    "    input_block=input_block,\n",
    "    prediction_tasks=prediction_task\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10588a6",
   "metadata": {},
   "source": [
    "#### Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b91c7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "model_mlp.compile(\n",
    "    optimizer=optimizer,\n",
    "    run_eagerly=True,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[100])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a9d3c",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1023e2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1799/1799 [==============================] - 166s 89ms/step - loss: 7.8337 - recall_at_100: 0.3696 - mrr_at_100: 0.0769 - ndcg_at_100: 0.1319 - map_at_100: 0.0769 - precision_at_100: 0.0037 - regularization_loss: 0.0000e+00 - val_loss: 7.8498 - val_recall_at_100: 0.4847 - val_mrr_at_100: 0.1169 - val_ndcg_at_100: 0.1880 - val_map_at_100: 0.1169 - val_precision_at_100: 0.0048 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1799/1799 [==============================] - 156s 86ms/step - loss: 7.5302 - recall_at_100: 0.4688 - mrr_at_100: 0.1177 - ndcg_at_100: 0.1854 - map_at_100: 0.1177 - precision_at_100: 0.0047 - regularization_loss: 0.0000e+00 - val_loss: 7.8187 - val_recall_at_100: 0.4964 - val_mrr_at_100: 0.1274 - val_ndcg_at_100: 0.1987 - val_map_at_100: 0.1274 - val_precision_at_100: 0.0050 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1799/1799 [==============================] - 156s 86ms/step - loss: 7.3839 - recall_at_100: 0.5157 - mrr_at_100: 0.1382 - ndcg_at_100: 0.2114 - map_at_100: 0.1382 - precision_at_100: 0.0052 - regularization_loss: 0.0000e+00 - val_loss: 7.8135 - val_recall_at_100: 0.5003 - val_mrr_at_100: 0.1340 - val_ndcg_at_100: 0.2049 - val_map_at_100: 0.1340 - val_precision_at_100: 0.0050 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1799/1799 [==============================] - 157s 87ms/step - loss: 7.2857 - recall_at_100: 0.5444 - mrr_at_100: 0.1532 - ndcg_at_100: 0.2292 - map_at_100: 0.1532 - precision_at_100: 0.0054 - regularization_loss: 0.0000e+00 - val_loss: 7.8301 - val_recall_at_100: 0.4996 - val_mrr_at_100: 0.1376 - val_ndcg_at_100: 0.2078 - val_map_at_100: 0.1376 - val_precision_at_100: 0.0050 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1799/1799 [==============================] - 154s 85ms/step - loss: 7.2054 - recall_at_100: 0.5683 - mrr_at_100: 0.1656 - ndcg_at_100: 0.2441 - map_at_100: 0.1656 - precision_at_100: 0.0057 - regularization_loss: 0.0000e+00 - val_loss: 7.8496 - val_recall_at_100: 0.4976 - val_mrr_at_100: 0.1405 - val_ndcg_at_100: 0.2098 - val_map_at_100: 0.1405 - val_precision_at_100: 0.0050 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1799/1799 [==============================] - 156s 86ms/step - loss: 7.1343 - recall_at_100: 0.5889 - mrr_at_100: 0.1771 - ndcg_at_100: 0.2574 - map_at_100: 0.1771 - precision_at_100: 0.0059 - regularization_loss: 0.0000e+00 - val_loss: 7.8728 - val_recall_at_100: 0.4960 - val_mrr_at_100: 0.1424 - val_ndcg_at_100: 0.2112 - val_map_at_100: 0.1424 - val_precision_at_100: 0.0050 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1799/1799 [==============================] - 155s 86ms/step - loss: 7.0689 - recall_at_100: 0.6093 - mrr_at_100: 0.1874 - ndcg_at_100: 0.2699 - map_at_100: 0.1874 - precision_at_100: 0.0061 - regularization_loss: 0.0000e+00 - val_loss: 7.8986 - val_recall_at_100: 0.4926 - val_mrr_at_100: 0.1437 - val_ndcg_at_100: 0.2116 - val_map_at_100: 0.1437 - val_precision_at_100: 0.0049 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1799/1799 [==============================] - 156s 86ms/step - loss: 7.0071 - recall_at_100: 0.6283 - mrr_at_100: 0.1974 - ndcg_at_100: 0.2818 - map_at_100: 0.1974 - precision_at_100: 0.0063 - regularization_loss: 0.0000e+00 - val_loss: 7.9262 - val_recall_at_100: 0.4897 - val_mrr_at_100: 0.1444 - val_ndcg_at_100: 0.2118 - val_map_at_100: 0.1444 - val_precision_at_100: 0.0049 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1799/1799 [==============================] - 154s 85ms/step - loss: 6.9476 - recall_at_100: 0.6473 - mrr_at_100: 0.2076 - ndcg_at_100: 0.2940 - map_at_100: 0.2076 - precision_at_100: 0.0065 - regularization_loss: 0.0000e+00 - val_loss: 7.9650 - val_recall_at_100: 0.4855 - val_mrr_at_100: 0.1453 - val_ndcg_at_100: 0.2116 - val_map_at_100: 0.1453 - val_precision_at_100: 0.0049 - val_regularization_loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1799/1799 [==============================] - 158s 87ms/step - loss: 6.8917 - recall_at_100: 0.6659 - mrr_at_100: 0.2172 - ndcg_at_100: 0.3055 - map_at_100: 0.2172 - precision_at_100: 0.0067 - regularization_loss: 0.0000e+00 - val_loss: 8.0177 - val_recall_at_100: 0.4807 - val_mrr_at_100: 0.1449 - val_ndcg_at_100: 0.2105 - val_map_at_100: 0.1449 - val_precision_at_100: 0.0048 - val_regularization_loss: 0.0000e+00\n",
      "CPU times: user 28min 19s, sys: 1min 47s, total: 30min 7s\n",
      "Wall time: 26min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model_mlp.fit(\n",
    "    train_dl,\n",
    "    validation_data=valid,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    schema=schema_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e948bf",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e319b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 9s 64ms/step - loss: 8.0177 - recall_at_100: 0.5105 - mrr_at_100: 0.1510 - ndcg_at_100: 0.2210 - map_at_100: 0.1510 - precision_at_100: 0.0051 - regularization_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 8.017659187316895,\n",
       " 'recall_at_100': 0.4807376563549042,\n",
       " 'mrr_at_100': 0.1448851227760315,\n",
       " 'ndcg_at_100': 0.21048013865947723,\n",
       " 'map_at_100': 0.1448851227760315,\n",
       " 'precision_at_100': 0.004807377699762583,\n",
       " 'regularization_loss': 0.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.evaluate(valid_ds, batch_size=1024, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87f381ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(pred, df_agg, batch_size=1024, n_topk=100):\n",
    "    print('Mask Predictions')\n",
    "    print('Generate Top100 Recommendations')\n",
    "    out_pred = []\n",
    "    out_score = []\n",
    "    for i in range(0, pred.shape[0]//batch_size+1):\n",
    "        batch_start = (i)*batch_size\n",
    "        batch_end = min((i+1)*batch_size, pred.shape[0])\n",
    "        pred_tmp = pred[batch_start:batch_end]\n",
    "        cp_pred = cupy.asarray(pred_tmp)\n",
    "        pred_idx = cupy.argsort(-cp_pred)\n",
    "        pred_idx = cupy.asnumpy(pred_idx)\n",
    "        for j in range(pred_idx.shape[0]):\n",
    "            topk = []\n",
    "            score = []\n",
    "            for k in range(n_topk):\n",
    "                idx = pred_idx[j][k]\n",
    "                topk.append(idx)\n",
    "                score.append(pred_tmp[j][idx])\n",
    "            out_pred.append(topk)\n",
    "            out_score.append(score)\n",
    "    \n",
    "    print('Transform Top100 Recommendations')\n",
    "    metadata = df_agg[['session_id', 'purchase_id_first']].to_pandas().values.tolist()\n",
    "    out = []\n",
    "    for i, ex in enumerate(metadata):\n",
    "        session_id = ex[0]\n",
    "        purchase = ex[1]\n",
    "        for k in range(n_topk):\n",
    "            out.append([session_id, purchase, out_pred[i][k], out_score[i][k]])\n",
    "\n",
    "    df_rec = cudf.DataFrame(out)\n",
    "    df_rec.columns = ['session_id', 'purchased', 'rec', 'score']\n",
    "    return(df_rec)\n",
    "\n",
    "def evaluate(df, add_folds=False):\n",
    "    print('Model evaluation')\n",
    "    df = df.drop_duplicates(['session_id', 'rec'])\n",
    "    df = df.sort_values(['session_id', 'score'], ascending=False)\n",
    "    df['dummy'] = 1\n",
    "    df['rank'] = df[['session_id', 'dummy']].groupby('session_id').cumsum()\n",
    "    df = df[df['rank']<=100]\n",
    "    df.drop('dummy', inplace=True, axis=1)\n",
    "    df['mrr'] = 1/df['rank']\n",
    "    df.loc[df['purchased']!=df['rec'], 'mrr'] = 0\n",
    "    out = {}\n",
    "    mrr = df[df['purchased']==df['rec']]['mrr'].sum()/df['session_id'].drop_duplicates().shape[0]\n",
    "    out['total'] = mrr\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "953dab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 4s 42ms/step\n",
      "Mask Predictions\n",
      "Generate Top100 Recommendations\n",
      "Transform Top100 Recommendations\n",
      "Model evaluation\n",
      "MRR:  0.14488511239789104\n",
      "CPU times: user 51.9 s, sys: 12.1 s, total: 1min 3s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model_mlp.predict(valid, batch_size=1024, verbose=1)\n",
    "ddf = valid.to_ddf()\n",
    "ddf = ddf[['session_id', 'purchase_id_first']].compute()\n",
    "df_rec = generate_recommendations(predictions, ddf)\n",
    "val_mrr = evaluate(df_rec)['total']\n",
    "print('MRR: ',val_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06099b00",
   "metadata": {},
   "source": [
    "## Training Bi-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839653fd",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b44af163",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 1024 #512\n",
    "LEARNING_RATE = 3e-1\n",
    "CLIPNORM = True\n",
    "DROPOUT= 0.2 #0.01\n",
    "LABEL_SMOOTHING = 0.2\n",
    "TEMPERATURE_SCALING = 2\n",
    "OPTIMIZER_NAME = 'adam'\n",
    "LOSS='CategoricalCrossentropy'\n",
    "\n",
    "BI_LSTM_HIDDEN_DIM = 64\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b68fb",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Let's create a `BiLSTM Block`, that will have a `inputs` dictionary to send the sequence of interaction embeddings `input_sequence`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e78b0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(mm.Block):\n",
    "    def __init__(self, hidden_dim= 64, **kwargs):\n",
    "        self.hidden_dim = hidden_dim\n",
    "        lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=False, dropout=0.05,\n",
    "                                   kernel_regularizer=regularizers.l2(1e-4))\n",
    "        self.lstm = tf.keras.layers.Bidirectional(lstm)\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs, training=False, **kwargs) -> tf.Tensor:  \n",
    "        interactions = inputs['input_sequence']\n",
    "        sequence_representation = self.lstm(interactions)\n",
    "        return sequence_representation\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = input_shape['input_sequence']\n",
    "        return (input_shape[0], input_shape[1], self.hidden_dim*2)\n",
    "    \n",
    "    \n",
    "bilstm = BiLSTM(hidden_dim=BI_LSTM_HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551125cf",
   "metadata": {},
   "source": [
    "For the Bi-LSTM model, let's use only `item_id_list_seq` for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "159b2cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item_id_list_seq</td>\n",
       "      <td>(Tags.SEQUENCE, Tags.ITEM, Tags.ITEM_ID, Tags....</td>\n",
       "      <td>int64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23619</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purchase_id_first</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.TARGET)</td>\n",
       "      <td>int64</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id_purchase_id.parquet</td>\n",
       "      <td>23619.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23619</td>\n",
       "      <td>item_id_purchase_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'item_id_list_seq', 'tags': {<Tags.SEQUENCE: 'sequence'>, <Tags.ITEM: 'item'>, <Tags.ITEM_ID: 'item_id'>, <Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': True, 'is_ragged': False}, {'name': 'purchase_id_first', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.TARGET: 'target'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.item_id_purchase_id.parquet', 'embedding_sizes': {'cardinality': 23619.0, 'dimension': 450.0}, 'domain': {'min': 0, 'max': 23619, 'name': 'item_id_purchase_id'}}, 'dtype': dtype('int64'), 'is_list': False, 'is_ragged': False}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_model = train.schema.select_by_name(['item_id_list_seq', 'purchase_id_first'])\n",
    "schema_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a151720",
   "metadata": {},
   "source": [
    "#### Build the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d6937",
   "metadata": {},
   "source": [
    "Let's create a InputBlock which takes sequential features, concatenate them and return the sequence of interaction embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56b55008",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = InputBlock(\n",
    "        schema_model,\n",
    "        aggregation='concat',\n",
    "        seq=True,\n",
    "        max_seq_length=20,\n",
    "        embedding_options=mm.EmbeddingOptions(\n",
    "            embedding_dim_default=256,\n",
    "            infer_embedding_sizes=True,\n",
    "            infer_embedding_sizes_multiplier=2,\n",
    "            infer_embeddings_ensure_dim_multiple_of_8=True\n",
    "        ),\n",
    "        split_sparse=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29891330",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_block = mm.ParallelBlock({'input_sequence': inputs}).connect(bilstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483babaa",
   "metadata": {},
   "source": [
    "A MLPBlock to get the sequence of hidden representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcad5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_block = mm.MLPBlock(\n",
    "                [64, 32],\n",
    "                activation='relu',\n",
    "                no_activation_last_layer=True,\n",
    "                dropout=DROPOUT,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc9eee",
   "metadata": {},
   "source": [
    "A Multi-Classiffication Prediction head which has\n",
    "- Layer Normalization\n",
    "- Weight Tying\n",
    "- Labels as One-hot encoded vectors, used for label smoothing \n",
    "- Temperature Scaling to reduce the overconfidence of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c014e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_call = L2Norm().connect(\n",
    "    ItemsPredictionWeightTying(schema_model), \n",
    "    mm.LabelToOneHot(), \n",
    "    LogitsTemperatureScaler(temperature=TEMPERATURE_SCALING)\n",
    ")\n",
    "\n",
    "prediction_task = mm.MultiClassClassificationTask(\n",
    "    target_name=\"purchase_id_first\",\n",
    "    pre=prediction_call,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9127f36",
   "metadata": {},
   "source": [
    "Now, we connect all the blocks togther to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3614b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi_lstm = Model(dense_block, mlp_block, prediction_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31211efb",
   "metadata": {},
   "source": [
    "#### Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4edee4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    clipnorm=CLIPNORM\n",
    ")\n",
    "\n",
    "model_bi_lstm.compile(\n",
    "    optimizer=optimizer,\n",
    "    run_eagerly=True,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=LABEL_SMOOTHING),\n",
    "    metrics=mm.TopKMetricsAggregator.default_metrics(top_ks=[100])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e598f",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a6126dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 06:23:00.631926: I tensorflow/stream_executor/cuda/cuda_dnn.cc:379] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 131s 142ms/step - loss: 10.2243 - recall_at_100: 0.1718 - mrr_at_100: 0.0213 - ndcg_at_100: 0.0477 - map_at_100: 0.0213 - precision_at_100: 0.0017 - regularization_loss: 1.4159 - val_loss: 10.8529 - val_recall_at_100: 0.2108 - val_mrr_at_100: 0.0290 - val_ndcg_at_100: 0.0615 - val_map_at_100: 0.0290 - val_precision_at_100: 0.0021 - val_regularization_loss: 1.8728\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 121s 134ms/step - loss: 11.1808 - recall_at_100: 0.1776 - mrr_at_100: 0.0222 - ndcg_at_100: 0.0497 - map_at_100: 0.0222 - precision_at_100: 0.0018 - regularization_loss: 2.3790 - val_loss: 11.3215 - val_recall_at_100: 0.2182 - val_mrr_at_100: 0.0272 - val_ndcg_at_100: 0.0617 - val_map_at_100: 0.0272 - val_precision_at_100: 0.0022 - val_regularization_loss: 2.3580\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 124s 138ms/step - loss: 11.4790 - recall_at_100: 0.1805 - mrr_at_100: 0.0227 - ndcg_at_100: 0.0507 - map_at_100: 0.0227 - precision_at_100: 0.0018 - regularization_loss: 2.6898 - val_loss: 12.2739 - val_recall_at_100: 0.2118 - val_mrr_at_100: 0.0285 - val_ndcg_at_100: 0.0616 - val_map_at_100: 0.0285 - val_precision_at_100: 0.0021 - val_regularization_loss: 3.3104\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 124s 137ms/step - loss: 12.3759 - recall_at_100: 0.1831 - mrr_at_100: 0.0229 - ndcg_at_100: 0.0513 - map_at_100: 0.0229 - precision_at_100: 0.0018 - regularization_loss: 3.5997 - val_loss: 12.7626 - val_recall_at_100: 0.2152 - val_mrr_at_100: 0.0300 - val_ndcg_at_100: 0.0636 - val_map_at_100: 0.0300 - val_precision_at_100: 0.0022 - val_regularization_loss: 3.8414\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 124s 137ms/step - loss: 12.7663 - recall_at_100: 0.1844 - mrr_at_100: 0.0228 - ndcg_at_100: 0.0515 - map_at_100: 0.0228 - precision_at_100: 0.0018 - regularization_loss: 3.9898 - val_loss: 12.5975 - val_recall_at_100: 0.2217 - val_mrr_at_100: 0.0273 - val_ndcg_at_100: 0.0621 - val_map_at_100: 0.0273 - val_precision_at_100: 0.0022 - val_regularization_loss: 3.6727\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 123s 136ms/step - loss: 12.7859 - recall_at_100: 0.1861 - mrr_at_100: 0.0234 - ndcg_at_100: 0.0523 - map_at_100: 0.0234 - precision_at_100: 0.0019 - regularization_loss: 4.0216 - val_loss: 12.7387 - val_recall_at_100: 0.2065 - val_mrr_at_100: 0.0269 - val_ndcg_at_100: 0.0592 - val_map_at_100: 0.0269 - val_precision_at_100: 0.0021 - val_regularization_loss: 3.8049\n",
      "Epoch 8/10\n",
      "625/900 [===================>..........] - ETA: 35s - loss: 13.0817 - recall_at_100: 0.1733 - mrr_at_100: 0.0214 - ndcg_at_100: 0.0483 - map_at_100: 0.0214 - precision_at_100: 0.0017 - regularization_loss: 4.2670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model_bi_lstm.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    schema=schema_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1645c",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8a83c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 10s 88ms/step - loss: 13.1749 - recall_at_100: 0.2540 - mrr_at_100: 0.0351 - ndcg_at_100: 0.0750 - map_at_100: 0.0351 - precision_at_100: 0.0025 - regularization_loss: 4.2864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 13.174932479858398,\n",
       " 'recall_at_100': 0.22673992812633514,\n",
       " 'mrr_at_100': 0.029583772644400597,\n",
       " 'ndcg_at_100': 0.06532561033964157,\n",
       " 'map_at_100': 0.029583772644400597,\n",
       " 'precision_at_100': 0.002267398638650775,\n",
       " 'regularization_loss': 4.286446571350098}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bi_lstm.evaluate(valid_ds, batch_size=1024, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86ef86e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 5s 57ms/step\n",
      "Mask Predictions\n",
      "Generate Top100 Recommendations\n",
      "Transform Top100 Recommendations\n",
      "Model evaluation\n",
      "MRR:  0.029583778549516854\n",
      "CPU times: user 50.5 s, sys: 12.6 s, total: 1min 3s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model_bi_lstm.predict(valid, batch_size=1024, verbose=1)\n",
    "ddf = valid.to_ddf()\n",
    "ddf = ddf[['session_id', 'purchase_id_first']].compute()\n",
    "df_rec = generate_recommendations(predictions, ddf)\n",
    "val_mrr = evaluate(df_rec)['total']\n",
    "print('MRR: ',val_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa1061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
